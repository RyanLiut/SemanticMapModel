'''
Project: To generate a Semantic Map according to a feature Map
'''

import numpy as np
import pandas as pd
from SMM import SemanticMap

if __name__ == "__main__":
    # 例0: 测试使用
    tfM_0 = np.array([[1,1,0,0],
                      [0,1,1,0],
                      [0,1,0,1],
                      [0,0,1,1]])
    featNames_0 = ['A', 'B', 'C', 'D']
    # 例1: 方言中“敆”的功能
    tfM = np.array([[1,1,1,1,0,0,1,1],
                        [1,1,1,0,0,0,0,1],
                        [1,1,1,1,1,1,1,1],
                        [1,0,1,0,1,1,1,0],
                        [1,0,1,0,1,0,0,0],
                        [1,0,1,0,1,1,0,0],
                        [1,1,1,1,1,0,1,0],
                        [1,1,1,1,1,1,0,1],
                        [1,1,1,0,1,1,1,0]])

    featNames = ['附着', '判断', '处所', '让步', '场所', '终点', '进行体', '焦点标记']

    # 例2: 重复性副词
    tfM_4 = np.array([[0]+[1]*4+[1]*5+[0]*5+[1]*2+[0]*1, # ZH
                      [0]+[1]*2+[0]*3+[1]+[0]*7+[1]+[0]*2+[1],
                      [1]*2+[0]*5+[1]*4+[0]*2+[1,0,0]+[1,0],
                      [0]+[1]*4+[0,1]+[0]*4+[1,1]+[0]*5,

                      [1]*2+[0]*5+[1,0,1,1]+[0]*7, # TB
                      [0,0,1,1]+[0]*3+[1]+[0]*9+[1],

                      [1]*2+[0]*16, # EN
                      [1]*2+[0]*16,
                      [0]+[1]*2+[0]*3+[1]+[0]*10+[1],
                      [0]*3+[1]*3+[0,1,1]+[0]*7+[1,0],

                      [1,1]+[0]*5+[1,0,1,1]+[0,0,1]+[0]*4, # GE
                      [0]+[1]*5+[0,1,1]+[0,0,1]+[0]*3+[1,1,0],

                      [1,1]+[0]*9+[1]+[0]*6, # FR
                      [0]+[1]*4+[0]*13,

                      [1,1]+[0]*5+[1]+[0]*10, # RU
                      [0,1,1]+[0]*15,

                      [1,1]+[0]*5+[1,0,1]+[0]*8, #JP
                      [0,1,1]+[0]*15,
                      [0,0,0,1,1]+[0]*13,

                      [1,1]+[0]*5+[1]*3+[0]*8, #KO
                      [0]*4+[1]+[0]*13,
                      [0,1,1]+[0]*11+[1,0,0,1],
                      [0,0,1]+[0]*3+[1]+[0]*11,
                      [0]*3+[1]+[0,1]+[0]*12,

                      [1]+[0]*6+[1]*3+[0]*5+[1,1,0], #VI
                      [0]+[1]*3+[0]*14,
                      [0]*2+[1]*3+[0,0,1,0,1]+[0]*8,
                      [0,1,1]+[0,0,0,1]+[0]*7+[1]+[0]*3
    ])
    featNames_4 = ['类同', '补充', '重复', '延续', '更加', '减量', '还原', '条件', '任意', '极端', '严重', '无论', '上限', '顺承', '不协', '意外', '底限', '续话']#, '并列'] 
    # featNames_EN_4 = ['LT','BC', 'CF', 'YX', 'GJ', 'ZJ', 'JL', 'HY', 'TJ', 'RY', 'JD', 'YZ', 'WL', 'RB', 'SX', 'SC', 'BX', 'YW', 'DX', 'XH', 'BL']
    featNames_EN_4 = ['AF', 'SU', 'RE', 'CO', 'GD', 'DE', 'IS', 'CD', 'DC', 'PT', 'SC', 'WH', 'SE', 'SD', 'IC', 'UE', 'BL','DC']
    GT4 = np.zeros((len(featNames_4), len(featNames_4)))
    GT_inx = [(0,1), (0,7), (0,9), (1,2), (1,11), (1,13), (1,14), (2,3), (2,6), (2,12), (2,17), (3,4),(3,5), (3,7), (7,8), (7,9), (7,15), (8,16), (9,10)]
    print(GT4.shape)
    GT4[[i[0] for i in GT_inx], [i[1] for i in GT_inx]] = 1
    GT4 += GT4.T
    print(tfM_4.shape)

    # 例3: 重复性副词（延伸版）
    # df = pd.read_csv("data_output_0603.csv")
    # tfM_5 = df.iloc[:,2:-1].to_numpy()
    # featNames_5 = df.columns[2:-1]
    # assert len(featNames_5) == tfM_5.shape[1], print(len(featNames), tfM_5.shape[1])
    
    savePath = "output/CS4_wGT.pdf"
    SM = SemanticMap(tfM_4, featNames_EN_4,None, GT4)
    SM.get_optimal_SpanningTrees(acc_thr=0.80, figPath=savePath)
    # SM.visualizeSM_2D()

